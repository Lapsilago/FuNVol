{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8744c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "import numpy as np\n",
    "from scipy.special import ndtri\n",
    "import bisect\n",
    "from scipy.optimize import fsolve, brentq, root_scalar\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicIV:\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        \n",
    "        self.phi = model.fda_model.phi\n",
    "        self.psi = model.fda_model.psi\n",
    "        self.mean = model.fda_model.mean\n",
    "        \n",
    "        self.delta = model.delta\n",
    "        self.tau = model.tau\n",
    "        \n",
    "        self.delta_range = np.arange(0.01,1,step=0.01)\n",
    "        self.delta_range_t = self.__Transform_Delta__(self.delta_range)\n",
    "        \n",
    "        self.delta_t = self.__Transform_Delta__(self.delta)\n",
    "        self.tau_t = self.__Transform_Tau__(self.tau)\n",
    "        \n",
    "        self.tickers = model.tickers\n",
    "        self.K = model.K\n",
    "        \n",
    "        self.nrm = model.nrm\n",
    "        self.reg = model.reg\n",
    "        \n",
    "        self.b = model.b\n",
    "        \n",
    "    \n",
    "    def __Transform_Delta__(self, delta):\n",
    "        \n",
    "        return 2*delta-1\n",
    "    \n",
    "    def __Recover_Delta__(self, delta_t):\n",
    "        \n",
    "        return 0.5*delta_t+0.5\n",
    "    \n",
    "    def __Transform_Tau__(self, tau):\n",
    "        \n",
    "        return 2*np.sqrt(tau)/np.max(np.sqrt(self.tau)) - 1\n",
    "    \n",
    "    def __Recover_Tau__(self, tau_t):\n",
    "        \n",
    "        return np.square((tau_t+1)*np.max(np.sqrt(self.tau))*0.5) \n",
    "    \n",
    "    def __UnNormalise__(self, a, b, X):\n",
    "        \n",
    "        return  (X -a)/b\n",
    "        \n",
    "    def __Recover_IV__(self, ticker_idx, IV_t):\n",
    "        \n",
    "        return np.log(1+ np.exp(self.__UnNormalise__(*self.nrm[ticker_idx]['IV'], IV_t)))\n",
    "    \n",
    "    def __Plot_IV_Surfaces__(self, b, scenario, delta=np.arange(0.0,1.01,0.01), tau=np.arange(1/365, 731/365, 1/365), save_fig=True):\n",
    "        \n",
    "        delta_t = self.__Transform_Delta__(delta)\n",
    "        tau_t = self.__Transform_Tau__(tau)\n",
    "        \n",
    "        delta_grid_t, tau_grid_t = np.meshgrid(delta_t, tau_t)\n",
    "        delta_grid, tau_grid = np.meshgrid(delta, tau)\n",
    "        \n",
    "        def __Calculate_IV_on_Grid__(b):\n",
    "            \n",
    "            IV_fit = np.zeros((b.shape[0], b.shape[1], delta_grid.shape[0], delta_grid.shape[1]))\n",
    "            \n",
    "            IV_fit[:,:] = self.mean(delta_grid_t, tau_grid_t)\n",
    "            for i in range(b.shape[-1]):\n",
    "                IV_fit += np.matmul(b[:,:,i].reshape(-1,1), self.psi[i](delta_grid_t,tau_grid_t).reshape(1,-1)).reshape(b.shape[0], b.shape[1], delta_grid.shape[0], delta_grid.shape[1])\n",
    "\n",
    "            return IV_fit \n",
    "        \n",
    "        def __IV_Per_Ticker__(b, ticker_idx):\n",
    "            \n",
    "            b = b[:,:,:-1]\n",
    "            IV_t = __Calculate_IV_on_Grid__(b=b)\n",
    "            IV = self.__Recover_IV__(ticker_idx, IV_t) \n",
    "            \n",
    "            return IV\n",
    "            \n",
    "        seq_length = int(b.shape[-1]/len(self.tickers))\n",
    "        IV = []\n",
    "        \n",
    "        for i in range(len(self.tickers)):\n",
    "            \n",
    "            IV_i = __IV_Per_Ticker__(b[:,:,i*seq_length:(i+1)*seq_length], i) \n",
    "            IV.append(IV_i)\n",
    "\n",
    "        filenames = []\n",
    "         \n",
    "        for j in range(b.shape[1]):\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(30,10), nrows=1, ncols=4, subplot_kw={\"projection\":\"3d\"})\n",
    "            if j==0:\n",
    "                fig.suptitle('Day 0 (last observed surface)', color='k', size=40)\n",
    "            else:\n",
    "                fig.suptitle('Day %s' %j, color='k', size=40)\n",
    "            \n",
    "            for i in range(len(self.tickers)):\n",
    "                \n",
    "                ax[i].xaxis.set_major_locator(plt.MaxNLocator(4))\n",
    "                ax[i].yaxis.set_major_locator(plt.MaxNLocator(4))\n",
    "                ax[i].zaxis.set_major_locator(plt.MaxNLocator(4))\n",
    "                ax[i].plot_surface(delta_grid, tau_grid, IV[i][0,j], linewidth=0, cmap=cm.coolwarm, antialiased=True)\n",
    "                ax[i].set_zlim(round(np.min(IV[i][0]),1)-0.1, np.ceil(np.max(IV[i][0])*10)/10)\n",
    "                ax[i].tick_params(axis='both', which='major', labelsize=20)\n",
    "                ax[i].tick_params(axis='z', which='major', labelsize=20, pad=10)\n",
    "                ax[i].set_title(self.tickers[i], fontsize=40)\n",
    "                \n",
    "                if i==0:\n",
    "                    ax[i].set_ylabel(r\"$\\tau$\", fontsize=30, labelpad=20)\n",
    "                    ax[i].set_xlabel(r\"$\\delta$\", fontsize=30, labelpad=20)\n",
    "                    ax[i].set_zlabel(r\"$\\sigma$\", fontsize=30, labelpad=25)\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "            filename = \"Simulated_\" + str(j) + \".png\"\n",
    "            filenames.append(filename)\n",
    "            if save_fig:\n",
    "                fig.savefig(filename) \n",
    "            \n",
    "            with imageio.get_writer('iv_scenario_%s.gif' %scenario, mode='I', fps=2, loop=1) as writer:\n",
    "                for filename in filenames:\n",
    "                    image = imageio.imread(filename)\n",
    "                    writer.append_data(image)\n",
    "            \n",
    "        return delta_grid, tau_grid, IV\n",
    "    \n",
    "    def __Plot_Price_Path__(self, price, scenario, save_fig=True):\n",
    "        \n",
    "        fig = plt.figure(figsize=(20, 5))\n",
    "        \n",
    "        for i in range(len(self.tickers)):\n",
    "            \n",
    "            plt.subplot(1,4,i+1)\n",
    "            plt.plot(price[:, i])\n",
    "            plt.title(model.tickers[i], fontsize=25)\n",
    "            plt.xticks(fontsize=15)\n",
    "            # plt.yticks(fontsize=15)\n",
    "            \n",
    "            if i==0:\n",
    "                plt.ylabel('Price', fontsize=20)\n",
    "                plt.yticks(fontsize=15)\n",
    "            if i==1:\n",
    "                plt.yticks(fontsize=15)\n",
    "            if i==2:\n",
    "                plt.yticks(fontsize=15)\n",
    "            if i==3:\n",
    "                plt.yticks(fontsize=15)\n",
    "                \n",
    "            \n",
    "            # plt.locator_params(axis='y', nbins=4)\n",
    "\n",
    "        plt.tight_layout(pad=1.5)\n",
    "        fig.supxlabel('Days', y=0.001, fontsize=18)\n",
    "        if save_fig:\n",
    "            plt.savefig(\"price_scenario_%s\" %scenario)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25fb64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "with open('dynamicIV.pkl', 'rb') as inp:    \n",
    "    model = pickle.load(inp)\n",
    "    \n",
    "# load the simulated FPC coefficients and transformed prices\n",
    "with open('sim_data_coeffs.npy', 'rb') as f:\n",
    "    b_sim = np.load(f)\n",
    "    \n",
    "\"\"\" b_sim is 5000 x 30 x36 dimensional\n",
    "The first index upto 5000 corresponds to 5000 generated (independent) scenarios\n",
    "The second index corresponds to the sequence of days where day 0 is the last day of training (observed) and the remaining 29 days are generated coefficients\n",
    "Hence day 0 will give the FPC coefficients (FPCCs) for the IV surface that is observed on the last day of training and is not a synthetic generated surface\n",
    "The last index corresponds to the different assets' FPCCs and transformed equity prices, details for third index below:\n",
    "0-7 give FPCCs for AMZN, 8 gives transformed equity price for AMZN\n",
    "9-16 give FPCCs for IBM, 17 gives transformed equity price for IBM\n",
    "18-25 give FPCCs for INTC, 26 gives transformed equity price for INTC\n",
    "27-34 give FPCCs for TSLA, 35 gives transformed equity price for TSLA \"\"\"\n",
    "\n",
    "with open('sim_data_prices.npy', 'rb') as f:\n",
    "    price_sim = np.load(f)\n",
    "    \n",
    "\"\"\" price_sim is 5000 x 30 x 4\n",
    "The first index upto 5000 corresponds to 5000 generated (independent) scenarios\n",
    "The second index corresponds to the sequence of days where day 0 is the last day of training (observed) and the remaining 29 days are generated coefficients\n",
    "The last index correspond to the different equities \"\"\"\n",
    "\n",
    "\"\"\" To get the IV surfaces as well as its values on a grid for scenario k\"\"\"\n",
    "k = 50\n",
    "delta_grid, tau_grid, IV = model.__Plot_IV_Surfaces__(b_sim[k:k+1,:,:], scenario=k+1, delta=np.arange(0.0,1.01,0.05), tau=np.arange(1/365, 731/365, 30/365))\n",
    "\n",
    "\"\"\" To get the price path plots for scenario k\"\"\"\n",
    "model.__Plot_Price_Path__(price_sim[k],k+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
